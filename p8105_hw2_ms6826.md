p8105_hw2_ms6826
================
2024-09-26

Libraries loaded

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(readxl)
```

## Problem 1

Reading/cleaning data

``` r
nyc_df= 
  read_csv(file="./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", na = c(".", "NA", "")) |> 
  janitor::clean_names() |> 
  mutate(across(route8:route11, as.character)) |> 
  mutate(
    entry = case_match(
      entry,
      "YES" ~ TRUE,
      "NO" ~ FALSE
    )) |> 
  select(line, station_name, station_latitude, station_longitude, starts_with("route"), entry, vending, entrance_type, ada) 
```

    ## Rows: 1868 Columns: 32
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (22): Division, Line, Station Name, Route1, Route2, Route3, Route4, Rout...
    ## dbl  (8): Station Latitude, Station Longitude, Route8, Route9, Route10, Rout...
    ## lgl  (2): ADA, Free Crossover
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
nyc_df
```

    ## # A tibble: 1,868 × 19
    ##    line     station_name station_latitude station_longitude route1 route2 route3
    ##    <chr>    <chr>                   <dbl>             <dbl> <chr>  <chr>  <chr> 
    ##  1 4 Avenue 25th St                  40.7             -74.0 R      <NA>   <NA>  
    ##  2 4 Avenue 25th St                  40.7             -74.0 R      <NA>   <NA>  
    ##  3 4 Avenue 36th St                  40.7             -74.0 N      R      <NA>  
    ##  4 4 Avenue 36th St                  40.7             -74.0 N      R      <NA>  
    ##  5 4 Avenue 36th St                  40.7             -74.0 N      R      <NA>  
    ##  6 4 Avenue 45th St                  40.6             -74.0 R      <NA>   <NA>  
    ##  7 4 Avenue 45th St                  40.6             -74.0 R      <NA>   <NA>  
    ##  8 4 Avenue 45th St                  40.6             -74.0 R      <NA>   <NA>  
    ##  9 4 Avenue 45th St                  40.6             -74.0 R      <NA>   <NA>  
    ## 10 4 Avenue 53rd St                  40.6             -74.0 R      <NA>   <NA>  
    ## # ℹ 1,858 more rows
    ## # ℹ 12 more variables: route4 <chr>, route5 <chr>, route6 <chr>, route7 <chr>,
    ## #   route8 <chr>, route9 <chr>, route10 <chr>, route11 <chr>, entry <lgl>,
    ## #   vending <chr>, entrance_type <chr>, ada <lgl>

This dataset contains information about each distinct NYC subway station
(including the multiple entrances for each station). I imported the
dataset and used the janitor::clean names function to change the column
names to all lowercase/remove any spaces and the na=c() function makes
sure any missing values will be labelled as “NA”. I used the mutate
function to combine the routes tables into one table that lists all of
the routes served and also used the mutate function to convert the entry
column from a character to a logical variable. I used the select
function to only include information on the name of the train station,
its specific location(latitude/longitude), the routes the station
serves, the street or avenue the train line runs along, whether or not
the train has vending machines for subway cards, the type of entrance to
get to the subway (e.g, stairs, elevator, etc.), whether there is an
entrance at that location (variable entry), and if the station is ADA
compliant. The data appears more tidy than it did before, but it will
not be tidy until’route’ variables are converted from wide to long
format. Since I did not retain information on the entrance locations for
each station (e.g., corner, entrance_location, etc.), however, some of
the data lines appear to be the same without the entrance location
information. The dimensions are 1868 columns x 9 rows.

``` r
nyc_df |> 
  select(station_name, line) |> 
  distinct()
```

    ## # A tibble: 465 × 2
    ##    station_name             line    
    ##    <chr>                    <chr>   
    ##  1 25th St                  4 Avenue
    ##  2 36th St                  4 Avenue
    ##  3 45th St                  4 Avenue
    ##  4 53rd St                  4 Avenue
    ##  5 59th St                  4 Avenue
    ##  6 77th St                  4 Avenue
    ##  7 86th St                  4 Avenue
    ##  8 95th St                  4 Avenue
    ##  9 9th St                   4 Avenue
    ## 10 Atlantic Av-Barclays Ctr 4 Avenue
    ## # ℹ 455 more rows

There are 465 distinct stations.

``` r
nyc_df |> 
  filter(ada == TRUE) |> 
  select(station_name, line) |> 
  distinct()
```

    ## # A tibble: 84 × 2
    ##    station_name                   line           
    ##    <chr>                          <chr>          
    ##  1 Atlantic Av-Barclays Ctr       4 Avenue       
    ##  2 DeKalb Av                      4 Avenue       
    ##  3 Pacific St                     4 Avenue       
    ##  4 Grand Central                  42nd St Shuttle
    ##  5 34th St                        6 Avenue       
    ##  6 47-50th Sts Rockefeller Center 6 Avenue       
    ##  7 Church Av                      6 Avenue       
    ##  8 21st St                        63rd Street    
    ##  9 Lexington Av                   63rd Street    
    ## 10 Roosevelt Island               63rd Street    
    ## # ℹ 74 more rows

There are 84 distinct stations that have ADA compliance.

``` r
nyc_df |> 
  filter(vending == "NO") |> 
  pull(entry) |> 
  mean()
```

    ## [1] 0.3770492

The proportion of station entrances/exists that have no vending but
allow entrance is 0.377.

Reformatting data

``` r
nyc_reformat= 
  read_csv(file="./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", na = c(".", "NA", "")) |> 
  janitor::clean_names() |> 
  mutate(across(route8:route11, as.character)) |>  
  pivot_longer(
    cols = route1:route11,
    names_to = "route_number",
    values_to = "route_name" ,
    values_drop_na = TRUE,
    names_prefix = "route"
  ) 
```

    ## Rows: 1868 Columns: 32
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (22): Division, Line, Station Name, Route1, Route2, Route3, Route4, Rout...
    ## dbl  (8): Station Latitude, Station Longitude, Route8, Route9, Route10, Rout...
    ## lgl  (2): ADA, Free Crossover
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
nyc_reformat |> 
  filter(route_name == "A") |> 
  select(station_name, line) |> 
  distinct()
```

    ## # A tibble: 60 × 2
    ##    station_name                  line           
    ##    <chr>                         <chr>          
    ##  1 Times Square                  42nd St Shuttle
    ##  2 125th St                      8 Avenue       
    ##  3 145th St                      8 Avenue       
    ##  4 14th St                       8 Avenue       
    ##  5 168th St - Washington Heights 8 Avenue       
    ##  6 175th St                      8 Avenue       
    ##  7 181st St                      8 Avenue       
    ##  8 190th St                      8 Avenue       
    ##  9 34th St                       8 Avenue       
    ## 10 42nd St                       8 Avenue       
    ## # ℹ 50 more rows

60 distinct stations serve the A train

``` r
nyc_reformat |> 
  filter(route_name == "A", ada == TRUE) |> 
  select(station_name, line) |> 
  distinct()
```

    ## # A tibble: 17 × 2
    ##    station_name                  line            
    ##    <chr>                         <chr>           
    ##  1 14th St                       8 Avenue        
    ##  2 168th St - Washington Heights 8 Avenue        
    ##  3 175th St                      8 Avenue        
    ##  4 34th St                       8 Avenue        
    ##  5 42nd St                       8 Avenue        
    ##  6 59th St                       8 Avenue        
    ##  7 Inwood - 207th St             8 Avenue        
    ##  8 West 4th St                   8 Avenue        
    ##  9 World Trade Center            8 Avenue        
    ## 10 Times Square-42nd St          Broadway        
    ## 11 59th St-Columbus Circle       Broadway-7th Ave
    ## 12 Times Square                  Broadway-7th Ave
    ## 13 8th Av                        Canarsie        
    ## 14 Franklin Av                   Franklin        
    ## 15 Euclid Av                     Fulton          
    ## 16 Franklin Av                   Fulton          
    ## 17 Howard Beach                  Rockaway

Of the 60 distinct stations that serve the A train, 17 of them are ADA
compliant.

## Problem 2

Read/clean Mr. Trash Wheel dataset

``` r
mrtrash_df=
  read_excel("data/202409 Trash Wheel Collection Data.xlsx", 1, range = "A2:N586") |>
  janitor::clean_names() |> 
  mutate(across(year:date, as.character)) |> 
  mutate(sports_balls= round(sports_balls)) |> 
  mutate(across(sports_balls, as.integer)) |> 
  mutate(dumpname= "mrtrashwheel") |> 
 select(dumpname, everything())
```

Read/clean Professor Trash Wheel dataset

``` r
protrash_df=
  read_excel("data/202409 Trash Wheel Collection Data.xlsx", na = c("NA", "", "."), 2, range = "A2:M108") |> 
  janitor::clean_names() |> 
  mutate(across(year:date, as.character)) |> 
  mutate(dumpname= "proftrash") |> 
  select(dumpname, everything())
```

Read/clean Gwynnda Trash Wheel dataset

``` r
gwynndatrash_df=
  read_excel("data/202409 Trash Wheel Collection Data.xlsx", na = c("NA", "", "."), 4, range = "A2:L157") |>
  janitor::clean_names() |> 
  mutate(across(year:date, as.character)) |> 
  mutate(dumpname= "gwynnda") |> 
  select(dumpname, everything())
```

Combining trash wheel datasets

``` r
trash_df=
  bind_rows(mrtrash_df, protrash_df, gwynndatrash_df) |> 
  select(dumpname, everything())
```

There are 15 variables in the resulting dataset of 845 dumpsters. Some
key variables are the dumpname (Mr. Trash Wheel, Professor Trash Wheel,
and Gwynnda Trash Wheel), the weight of trash collected, as well as some
items that have been collected by the trash wheels such as plastic
bottles and cigarette butts. It appears that over the years Mr. Trash
Wheel often collects the highest weight of trash and on average powers
the most homes. Professor Trash, interestingly, seems to often collect
the greatest number of water bottles.

``` r
trash_df |> 
  filter(dumpname == "proftrash") |> 
  summarise(sum(weight_tons, na.rm = TRUE))
```

    ## # A tibble: 1 × 1
    ##   `sum(weight_tons, na.rm = TRUE)`
    ##                              <dbl>
    ## 1                             216.

The total weight collected by Prof Trash Wheel is 216 tons.

``` r
trash_df |> 
   filter(dumpname == "gwynnda", month == "June", year == "2022" ) |> 
  summarise(sum(cigarette_butts, na.rm=TRUE))
```

    ## # A tibble: 1 × 1
    ##   `sum(cigarette_butts, na.rm = TRUE)`
    ##                                  <dbl>
    ## 1                                18120

The total number of cigarette butts collected by Gwynnda in June 2022 is
18,120.

## Problem 3

Importing/cleaning/tidying bakers, bakes, and results .csv files

``` r
bakers_df=
  read_csv(file="./data/bakers.csv") |> 
  janitor::clean_names() |> 
  mutate(
    baker_name=str_to_lower(baker_name),
    baker_occupation= str_to_lower(baker_occupation),
    hometown= str_to_lower(hometown)
  ) |> 
  separate(baker_name, into = c("baker", "baker_lastname"),sep= " ")
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
bakes_df=
  read_csv(file="./data/bakes.csv", na = c("N/A", "NA", "", "Unknown", "unknown", "UNKNOWN")) |> 
  janitor::clean_names() |> 
  mutate(
    baker=str_to_lower(baker),
    signature_bake= str_to_lower(signature_bake),
    show_stopper= str_to_lower(show_stopper)
  ) |> 
  mutate(baker = gsub('"', '', baker)) 
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
results_df=
  read_csv(file="./data/results.csv", na = c(".", "NA", ""), skip=2) |> 
  janitor::clean_names() |> 
  mutate(
    baker=str_to_lower(baker),
   result= str_to_lower(result),
  ) 
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Checking for discrepancies

``` r
anti_join(bakes_df, bakers_df, by="baker")
```

    ## # A tibble: 0 × 5
    ## # ℹ 5 variables: series <dbl>, episode <dbl>, baker <chr>,
    ## #   signature_bake <chr>, show_stopper <chr>

``` r
anti_join(results_df, bakers_df, by= "baker")
```

    ## # A tibble: 8 × 5
    ##   series episode baker  technical result    
    ##    <dbl>   <dbl> <chr>      <dbl> <chr>     
    ## 1      2       1 joanne        11 in        
    ## 2      2       2 joanne        10 in        
    ## 3      2       3 joanne         1 in        
    ## 4      2       4 joanne         8 in        
    ## 5      2       5 joanne         6 in        
    ## 6      2       6 joanne         1 star baker
    ## 7      2       7 joanne         3 in        
    ## 8      2       8 joanne         1 winner

``` r
anti_join(bakes_df, bakers_df, by="series")
```

    ## # A tibble: 0 × 5
    ## # ℹ 5 variables: series <dbl>, episode <dbl>, baker <chr>,
    ## #   signature_bake <chr>, show_stopper <chr>

``` r
anti_join(results_df, bakers_df, by= "series")
```

    ## # A tibble: 0 × 5
    ## # ℹ 5 variables: series <dbl>, episode <dbl>, baker <chr>, technical <dbl>,
    ## #   result <chr>

``` r
anti_join(bakes_df, results_df, by="baker")
```

    ## # A tibble: 8 × 5
    ##   series episode baker signature_bake                               show_stopper
    ##    <dbl>   <dbl> <chr> <chr>                                        <chr>       
    ## 1      2       1 jo    chocolate orange cupcakesorange and cardamo… chocolate a…
    ## 2      2       2 jo    caramelised onion, gruyere and thyme quiche  raspberry a…
    ## 3      2       3 jo    stromboli flavored with mozzarella, ham, an… <NA>        
    ## 4      2       4 jo    lavender biscuits                            blueberry m…
    ## 5      2       5 jo    salmon and asparagus pie                     apple and r…
    ## 6      2       6 jo    rum and raisin baked cheesecake              limoncello …
    ## 7      2       7 jo    raspberry & strawberry mousse cake           pain aux ra…
    ## 8      2       8 jo    raspberry and blueberry mille feuille        mini victor…

``` r
anti_join(bakes_df, results_df, by="series")
```

    ## # A tibble: 0 × 5
    ## # ℹ 5 variables: series <dbl>, episode <dbl>, baker <chr>,
    ## #   signature_bake <chr>, show_stopper <chr>

``` r
results_df=
results_df |> 
  mutate(baker= ifelse(baker == "joanne", "jo", baker)) |> 
  mutate(result= ifelse(baker== "diana" & episode >5, NA, result)) |> 
  drop_na(result)
```

Combining datasets

``` r
british_df=
   full_join(results_df, bakes_df, by= c("series", "episode", "baker")) |> 
  full_join(x=_, bakers_df, by=c("series", "baker")) |> 
  select(baker, baker_lastname, baker_age, series, episode, everything() )

write.csv(british_df, "data/british.csv")
```

I made any missing values, unknowns, UNKNOWNS, NAs, etc. all NAs in
bakes_df and results_df. I got rid of the quotes around jo’s name in
bakes_df and changed joanne to nickname jo in results_df. Also, since
diana drops out in episode 5, I made “diana” “NA” if above episode 5 and
removed those data points with drop_na in results_df. Also I separated
the ‘baker_name’ variable to first (‘baker’) and last name
(‘baker_lastname’) in bakers_df so ‘baker’ would be consistent with
other datasets. The final dataset combines the three datasets, where I
first joined results_df and bakes_df by their shared variables and then
used this result to also join bakers_df by the variables all three
datasets have in common (‘series’ and ‘baker’) and selected baker,
baker_lastname, baker_age, series, and episode to read first.

Reader-friendly table

``` r
british_df |> 
  filter(result %in% c("star baker", "winner"), series>4) |> 
  select(baker, series, result) |> 
  knitr::kable()
```

| baker     | series | result     |
|:----------|-------:|:-----------|
| nancy     |      5 | star baker |
| richard   |      5 | star baker |
| luis      |      5 | star baker |
| richard   |      5 | star baker |
| kate      |      5 | star baker |
| chetna    |      5 | star baker |
| richard   |      5 | star baker |
| richard   |      5 | star baker |
| richard   |      5 | star baker |
| nancy     |      5 | winner     |
| marie     |      6 | star baker |
| ian       |      6 | star baker |
| ian       |      6 | star baker |
| ian       |      6 | star baker |
| nadiya    |      6 | star baker |
| mat       |      6 | star baker |
| tamal     |      6 | star baker |
| nadiya    |      6 | star baker |
| nadiya    |      6 | star baker |
| nadiya    |      6 | winner     |
| jane      |      7 | star baker |
| candice   |      7 | star baker |
| tom       |      7 | star baker |
| benjamina |      7 | star baker |
| candice   |      7 | star baker |
| tom       |      7 | star baker |
| andrew    |      7 | star baker |
| candice   |      7 | star baker |
| andrew    |      7 | star baker |
| candice   |      7 | winner     |
| steven    |      8 | star baker |
| steven    |      8 | star baker |
| julia     |      8 | star baker |
| kate      |      8 | star baker |
| sophie    |      8 | star baker |
| liam      |      8 | star baker |
| steven    |      8 | star baker |
| stacey    |      8 | star baker |
| sophie    |      8 | star baker |
| sophie    |      8 | winner     |
| manon     |      9 | star baker |
| rahul     |      9 | star baker |
| rahul     |      9 | star baker |
| dan       |      9 | star baker |
| kim-joy   |      9 | star baker |
| briony    |      9 | star baker |
| kim-joy   |      9 | star baker |
| ruby      |      9 | star baker |
| ruby      |      9 | star baker |
| rahul     |      9 | winner     |
| michelle  |     10 | star baker |
| alice     |     10 | star baker |
| michael   |     10 | star baker |
| steph     |     10 | star baker |
| steph     |     10 | star baker |
| steph     |     10 | star baker |
| henry     |     10 | star baker |
| steph     |     10 | star baker |
| alice     |     10 | star baker |
| david     |     10 | winner     |

I would have maybe expected richard to win since he had won star baker
so many times. Since nadiya and candace both won star baker several
times in their seasons, it makes sense that she won. Also, I am
surprised david was a winner since he did not win star baker.

Import, clean, tidy, and organize the viewership data

``` r
viewers_df=
  read_csv(file="./data/viewers.csv", na = c("NA")) |> 
  janitor::clean_names()
```

    ## Rows: 10 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (11): Episode, Series 1, Series 2, Series 3, Series 4, Series 5, Series ...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Show first 10 rows

``` r
head(viewers_df, 10)
```

    ## # A tibble: 10 × 11
    ##    episode series_1 series_2 series_3 series_4 series_5 series_6 series_7
    ##      <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>
    ##  1       1     2.24     3.1      3.85     6.6      8.51     11.6     13.6
    ##  2       2     3        3.53     4.6      6.65     8.79     11.6     13.4
    ##  3       3     3        3.82     4.53     7.17     9.28     12.0     13.0
    ##  4       4     2.6      3.6      4.71     6.82    10.2      12.4     13.3
    ##  5       5     3.03     3.83     4.61     6.95     9.95     12.4     13.1
    ##  6       6     2.75     4.25     4.82     7.32    10.1      12       13.1
    ##  7       7    NA        4.42     5.1      7.76    10.3      12.4     13.4
    ##  8       8    NA        5.06     5.35     7.41     9.02     11.1     13.3
    ##  9       9    NA       NA        5.7      7.41    10.7      12.6     13.4
    ## 10      10    NA       NA        6.74     9.45    13.5      15.0     15.9
    ## # ℹ 3 more variables: series_8 <dbl>, series_9 <dbl>, series_10 <dbl>

``` r
viewers_df |> 
  summarise(mean(series_1, na.rm=TRUE))
```

    ## # A tibble: 1 × 1
    ##   `mean(series_1, na.rm = TRUE)`
    ##                            <dbl>
    ## 1                           2.77

Mean viewers for season 1 is 2.77.

``` r
viewers_df |> 
  summarise(mean(series_5))
```

    ## # A tibble: 1 × 1
    ##   `mean(series_5)`
    ##              <dbl>
    ## 1             10.0

Mean viewers for season 5 is 10.0.
