---
title: "p8105_hw2_ms6826"
output: github_document
date: "2024-09-26"
---

Libraries loaded
```{r}
library(tidyverse)
library(readxl)
```

## Problem 1

Reading/cleaning data
```{r}
nyc_df= 
  read_csv(file="./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", na = c(".", "NA", "")) |> 
  janitor::clean_names() |> 
  mutate(across(route8:route11, as.character)) |> 
  mutate(
    entry = case_match(
      entry,
      "YES" ~ TRUE,
      "NO" ~ FALSE
    )) |> 
  select(line, station_name, station_latitude, station_longitude, starts_with("route"), entry, vending, entrance_type, ada) 
nyc_df
```
This dataset contains information about each distinct NYC subway station (including the multiple entrances for each station). I imported the dataset and used the janitor::clean names function to change the column names to all lowercase/remove any spaces and the na=c() function makes sure any missing values will be labelled as "NA". I used the mutate function to combine the routes tables into one table that lists all of the routes served and also used the mutate function to convert the entry column from a character to a logical variable. I used the select function to only include information on the name of the train station, its specific location(latitude/longitude), the routes the station serves, the street or avenue the train line runs along, whether or not the train has vending machines for subway cards, the type of entrance to get to the subway (e.g, stairs, elevator, etc.), whether there is an entrance at that location (variable entry), and if the station is ADA compliant. The data appears more tidy than it did before, but it will not be tidy until'route' variables are converted from wide to long format. Since I did not retain  information on the entrance locations for each station (e.g., corner, entrance_location, etc.), however, some of the data lines appear to be the same without the entrance location information. The dimensions are 1868 columns x 9 rows.

```{r}
nyc_df |> 
  select(station_name, line) |> 
  distinct()
```
There are 465 distinct stations.

```{r}
nyc_df |> 
  filter(ada == TRUE) |> 
  select(station_name, line) |> 
  distinct()
```
There are 84 distinct stations that have ADA compliance.

```{r}
nyc_df |> 
  filter(vending == "NO") |> 
  pull(entry) |> 
  mean()

```
The proportion of station entrances/exists that have no vending but allow entrance is 0.377.


Reformatting data
```{r}
nyc_reformat= 
  read_csv(file="./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", na = c(".", "NA", "")) |> 
  janitor::clean_names() |> 
  mutate(across(route8:route11, as.character)) |>  
  pivot_longer(
    cols = route1:route11,
    names_to = "route_number",
    values_to = "route_name" ,
    values_drop_na = TRUE,
    names_prefix = "route"
  ) 
```

```{r}
nyc_reformat |> 
  filter(route_name == "A") |> 
  select(station_name, line) |> 
  distinct()
```
60 distinct stations serve the A train

```{r}
nyc_reformat |> 
  filter(route_name == "A", ada == TRUE) |> 
  select(station_name, line) |> 
  distinct()
```
Of the 60 distinct stations that serve the A train, 17 of them are ADA compliant.

## Problem 2

Read/clean Mr. Trash Wheel dataset
```{r}
mrtrash_df=
  read_excel("data/202409 Trash Wheel Collection Data.xlsx", 1, range = "A2:N586") |>
  janitor::clean_names() |> 
  mutate(across(year:date, as.character)) |> 
  mutate(sports_balls= round(sports_balls)) |> 
  mutate(across(sports_balls, as.integer)) |> 
  mutate(dumpname= "mrtrashwheel") |> 
 select(dumpname, everything())
```

Read/clean Professor Trash Wheel dataset
```{r}
protrash_df=
  read_excel("data/202409 Trash Wheel Collection Data.xlsx", na = c("NA", "", "."), 2, range = "A2:M108") |> 
  janitor::clean_names() |> 
  mutate(across(year:date, as.character)) |> 
  mutate(dumpname= "proftrash") |> 
  select(dumpname, everything())
```

Read/clean Gwynnda Trash Wheel dataset
```{r}
gwynndatrash_df=
  read_excel("data/202409 Trash Wheel Collection Data.xlsx", na = c("NA", "", "."), 4, range = "A2:L157") |>
  janitor::clean_names() |> 
  mutate(across(year:date, as.character)) |> 
  mutate(dumpname= "gwynnda") |> 
  select(dumpname, everything())
```

Combining trash wheel datasets
```{r}
trash_df=
  bind_rows(mrtrash_df, protrash_df, gwynndatrash_df) |> 
  select(dumpname, everything())

```
There are 15 variables in the resulting dataset of 845 dumpsters. Some key variables are the dumpname (Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda Trash Wheel), the weight of trash collected, as well as some items that have been collected by the trash wheels such as plastic bottles and cigarette butts. It appears that over the years Mr. Trash Wheel often collects the highest weight of trash and on average powers the most homes. Professor Trash, interestingly, seems to often collect the greatest number of water bottles. 


```{r}
trash_df |> 
  filter(dumpname == "proftrash") |> 
  summarise(sum(weight_tons, na.rm = TRUE))
```
The total weight collected by Prof Trash Wheel is 216 tons. 


```{r}
trash_df |> 
   filter(dumpname == "gwynnda", month == "June", year == "2022" ) |> 
  summarise(sum(cigarette_butts, na.rm=TRUE))
```
The total number of cigarette butts collected by Gwynnda in June 2022 is 18,120. 


## Problem 3

Importing/cleaning/tidying bakers, bakes, and results .csv files
```{r}
bakers_df=
  read_csv(file="./data/bakers.csv") |> 
  janitor::clean_names() |> 
  mutate(
    baker_name=str_to_lower(baker_name),
    baker_occupation= str_to_lower(baker_occupation),
    hometown= str_to_lower(hometown)
  ) |> 
  separate(baker_name, into = c("baker", "baker_lastname"),sep= " ")

```

```{r}
bakes_df=
  read_csv(file="./data/bakes.csv", na = c("N/A", "NA", "", "Unknown", "unknown", "UNKNOWN")) |> 
  janitor::clean_names() |> 
  mutate(
    baker=str_to_lower(baker),
    signature_bake= str_to_lower(signature_bake),
    show_stopper= str_to_lower(show_stopper)
  ) |> 
  mutate(baker = gsub('"', '', baker)) 
```

```{r}
results_df=
  read_csv(file="./data/results.csv", na = c(".", "NA", ""), skip=2) |> 
  janitor::clean_names() |> 
  mutate(
    baker=str_to_lower(baker),
   result= str_to_lower(result),
  ) 
```

Checking for discrepancies
```{r}
anti_join(bakes_df, bakers_df, by="baker")
anti_join(results_df, bakers_df, by= "baker")
anti_join(bakes_df, bakers_df, by="series")
anti_join(results_df, bakers_df, by= "series")
anti_join(bakes_df, results_df, by="baker")
anti_join(bakes_df, results_df, by="series")
```

```{r}
results_df=
results_df |> 
  mutate(baker= ifelse(baker == "joanne", "jo", baker)) |> 
  mutate(result= ifelse(baker== "diana" & episode >5, NA, result)) |> 
  drop_na(result)
```


Combining datasets
```{r}
british_df=
   full_join(results_df, bakes_df, by= c("series", "episode", "baker")) |> 
  full_join(x=_, bakers_df, by=c("series", "baker")) |> 
  select(baker, baker_lastname, baker_age, series, episode, everything() )

write.csv(british_df, "data/british.csv")
```
I made any missing values, unknowns, UNKNOWNS, NAs, etc. all NAs in bakes_df and results_df. I got rid of the quotes around jo's name in bakes_df and changed joanne to nickname jo in results_df. Also, since diana drops out in episode 5, I made "diana" "NA" if above episode 5 and removed those data points with drop_na in results_df. Also I separated the 'baker_name' variable to first ('baker') and last name ('baker_lastname') in bakers_df so 'baker' would be consistent with other datasets. The final dataset combines the three datasets, where I first joined results_df and bakes_df by their shared variables and then used this result to also join bakers_df by the variables all three datasets have in common ('series' and 'baker') and selected baker, baker_lastname, baker_age, series, and episode to read first.


Reader-friendly table  
```{r}
british_df |> 
  filter(result %in% c("star baker", "winner"), series>4) |> 
  select(baker, series, result) |> 
  knitr::kable()
```
I would have maybe expected richard to win since he had won star baker so many times. Since nadiya and candace both won star baker several times in their seasons, it makes sense that she won. Also, I am surprised david was a winner since he did not win star baker.



Import, clean, tidy, and organize the viewership data
```{r}
viewers_df=
  read_csv(file="./data/viewers.csv", na = c("NA")) |> 
  janitor::clean_names() |> 
  mutate(across(c(series_1:series_10), round)) |> 
  mutate(across(series_1:series_10, as.integer))
```

Show first 10 rows
```{r}
head(viewers_df, 10)
```

```{r}
viewers_df |> 
  summarise(mean(series_1, na.rm=TRUE))
```
Mean viewers for season 1 is 2.83.

```{r}
viewers_df |> 
  summarise(mean(series_5))
```
Mean viewers for season 5 is 10.1.




